{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Tutorial #1: Prompt vs. Pre-Train/Fine-Tune Methods in Text Classification and NER\n",
    "\n",
    "This tutorial will show how prompt-based learning can achieve superior results compared to head-based fine-tuning in data-sparse training situations. While prompting may not consistently outperform fine-tuning with more significant amounts of data and longer training cycles, prompt learning has a significant advantage in its efficiency. It allows LLMs to be adapted to new tasks more quickly and at a lower cost. It is far less dependent on data volume and quality, and fewer data means less expensive computation.\n",
    "\n",
    "Our experiment will directly compare the zero-shot and few-shot capabilities of the pre-train/fine-tune and prompt-based learning approaches in their application to text classification and named-entity recognition. We adopt BERT as the basis for our fine-tuning exercises for this test. Using PyTorch, supplemented with OpenPrompt for the prompt-based portion, we will iteratively refine our BERT models with larger and larger subsets of the training data, predicting on the validation sets at regular intervals to show how the model is responding to few-shot learning. Finally, we will compare learning curves for the two tuning approaches for each NLP task and discuss the implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cp4yv_6iVW_"
   },
   "source": [
    "## Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHC2u6uR6iWU"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.19.0\n",
    "!pip install datasets\n",
    "!pip install openprompt\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tlj4ZSPjAXGe"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BertForTokenClassification,\n",
    "    BertForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoTokenizer,\n",
    "    AdamW\n",
    ")\n",
    "\n",
    "from openprompt.data_utils import InputExample\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt.prompts import ManualTemplate, ManualVerbalizer\n",
    "from openprompt import PromptDataLoader, PromptForClassification\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMVHj_SFiVXF"
   },
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvjqkCREiVXF"
   },
   "source": [
    "### Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVpjgtn4iVXF",
    "outputId": "850a3144-2a6c-44b5-d038-5bab6b586c0d"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('glue', 'sst2')\n",
    "seed = 0\n",
    "\n",
    "## Keep only 1000 of the training data to speed up preprocessing/tokenization\n",
    "dataset['train'] = dataset['train'].shuffle(seed=seed).select(range(1000))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2clYqIvhiVXG"
   },
   "outputs": [],
   "source": [
    "## Separate the positives and negatives in training to ensure balanced samples.\n",
    "## This could matter a lot in few-shot\n",
    "dataset['pos_train'] = dataset['train'].filter(lambda x: x['label']==1)\n",
    "dataset['neg_train'] = dataset['train'].filter(lambda x: x['label']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_RK9g2AiVXG",
    "outputId": "ea4181bf-b373-4108-9eef-883e511dcf7b"
   },
   "outputs": [],
   "source": [
    "# we will try different samples evenly split between classes\n",
    "shot_increments = 5\n",
    "sample_sizes = [2**i for i in range(4, 4 + shot_increments)]\n",
    "sample_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYRGuYAviVXH"
   },
   "source": [
    "### Head-based fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "fc3675c8cdd34ea38ac3f9c07fd0f8fd",
      "43eddbbd7b994bf280259963d8b90a0e",
      "d3942f7ec3f44fb7b1cc36959b825420",
      "9f4371ee9536450e96dc2d404221e62f",
      "154f86fa79a24a878eab56c61be42a14",
      "471803e92edf48248a90d934549b2a89",
      "7e710035aecf4dcdb9a89f2a94706f45",
      "0b84311849f84b2f8ead61bee9fe76ae",
      "0958a86012ae4b8eb2bccc8773959acd",
      "ad433567c0dc4b16a4c7a78fe9d1d2d7",
      "b9bc96d64de94241a3727252642bf3ec"
     ]
    },
    "id": "5xe0_rM6iVXH",
    "outputId": "ba8979cc-20c0-4edc-8b1c-c37d68806d0f"
   },
   "outputs": [],
   "source": [
    "## Instantiate a BERT tokenizer and tokenizer the dataset\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence\"], truncation=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# rename columns and convert tokenized dataset to pytorch format\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWp8G0awiVXH"
   },
   "outputs": [],
   "source": [
    "## Define the accuracy metric\n",
    "\n",
    "def compute_acc(eval_preds):\n",
    "    preds = np.argmax(eval_preds.predictions, axis=-1)\n",
    "    labels = eval_preds.label_ids\n",
    "    acc = sum([int(i==j) for i,j in zip(preds, labels)])/len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245,
     "referenced_widgets": [
      "dd9e2008ea70466d8f763e59a6e71e81",
      "03a30e0f3629404fad68bca87cd7df83",
      "8ab2c16098b0433a8ee2bffc4533183a",
      "a2e31e39f305471f9ca3d12b7a5ca1bc",
      "d84a270ea3ea4156acc42a1fb79a233d",
      "bd09844151a54644b8a5c6cb7fc5ed29",
      "901f44c6889744859993aaeb6100056f",
      "91d59fe84a634ec293216cfaee9c333a",
      "e6781e07a6314e51b3fd91e3f6ed4ae8",
      "ae4146821f994598ab561b975ad2f9f2",
      "f31f50d874a046b294537c1fe6950fb7"
     ]
    },
    "id": "QMuLYiAXiVXH",
    "outputId": "ff88b13e-11a0-40fe-f117-386e8be32144"
   },
   "outputs": [],
   "source": [
    "## \"Zero-shot\" i.e. the head has random weights and no training is done\n",
    "training_args = TrainingArguments(\"trainer\")\n",
    "finetune_model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
    "if use_cuda:\n",
    "    finetune_model = finetune_model.cuda()\n",
    "\n",
    "trainer = Trainer(\n",
    "    finetune_model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "## Skip training of the Trainer object for zero-shot\n",
    "preds = trainer.predict(tokenized_datasets['validation'])\n",
    "acc = compute_acc(preds)\n",
    "finetune_scores = [acc]\n",
    "print(finetune_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Xz92P171iVXI",
    "outputId": "81678075-1a7f-4c41-c27d-18637dae9b05"
   },
   "outputs": [],
   "source": [
    "## Now generate a learning curve. loop over different values of k (total samples)\n",
    "## and calculate accuracy for each\n",
    "\n",
    "for k in sample_sizes:\n",
    "    train_sample = concatenate_datasets([tokenized_datasets['pos_train'].select(range(k)),\n",
    "                                         tokenized_datasets['neg_train'].select(range(k))])\n",
    "    training_args = TrainingArguments(\"trainer\")\n",
    "    model = copy.deepcopy(finetune_model)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            training_args,\n",
    "            train_dataset=train_sample,\n",
    "            # data_collator=data_collator,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "    trainer.train()\n",
    "    preds = trainer.predict(tokenized_datasets['validation'])\n",
    "    acc = compute_acc(preds)\n",
    "    finetune_scores.append(acc)\n",
    "    print(finetune_scores)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_EJLfR4iVXI"
   },
   "source": [
    "### Prompt-based fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gy6vCsrRiVXI",
    "outputId": "2abdddae-2dbd-4470-fa4e-0f2adb515ff4"
   },
   "outputs": [],
   "source": [
    "## Create a dataset of openprompt InputExamples from the training data\n",
    "prompt_dataset = {}\n",
    "for split in ['pos_train', 'neg_train', 'validation', 'test']:\n",
    "    prompt_dataset[split] = []\n",
    "    for data in dataset[split]:\n",
    "        input_example = InputExample(text_a = data['sentence'], label=int(data['label']), guid=data['idx'])\n",
    "        prompt_dataset[split].append(input_example)\n",
    "print(prompt_dataset['pos_train'][0])\n",
    "print(prompt_dataset['neg_train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9ev2o-QiVXI",
    "outputId": "ad2d9e9b-e6a8-4b4e-8f04-0f7c971a1bc3"
   },
   "outputs": [],
   "source": [
    "## Load the BERT model\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-cased\")\n",
    "\n",
    "## Create the prompt template\n",
    "template_text = '{\"placeholder\": \"text_a\"} it is {\"mask\"} .'\n",
    "template = ManualTemplate(tokenizer=tokenizer, text=template_text)\n",
    "\n",
    "## Create a wrapped tokenizer\n",
    "wrapped_tokenizer = WrapperClass(max_seq_length=128, decoder_max_length=3, tokenizer=tokenizer, truncate_method=\"head\")\n",
    "\n",
    "## Define your verbalizer with desired vocabulatary mapping to pos and neg\n",
    "verbalizer = ManualVerbalizer(tokenizer, num_classes=2,\n",
    "                              label_words=[['terrible'], ['great']])\n",
    "\n",
    "## Generate a testing dataloader\n",
    "val_dataloader = PromptDataLoader(prompt_dataset['validation'], template, tokenizer=tokenizer,\n",
    "                                  tokenizer_wrapper_class=WrapperClass, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iW6S9sDXiVXJ"
   },
   "outputs": [],
   "source": [
    "## Define the accuracy metric\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "    with torch.no_grad():\n",
    "        for step, inputs in enumerate(val_dataloader):\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "            logits = model(inputs)\n",
    "            labels = inputs['label']\n",
    "            alllabels.extend(labels.cpu().tolist())\n",
    "            allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "    acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jlgVoOKiVXJ",
    "outputId": "fd139e14-2401-4cd8-8eb3-52851d7afe45"
   },
   "outputs": [],
   "source": [
    "## ** Zero-shot testing **\n",
    "## Run the evalation set against the prompt model before any finetuning.\n",
    "## This is equivalent to normal prompt-based inference, relying just on\n",
    "## the weights tuned into the model and not on any modification.\n",
    "\n",
    "prompt_model = PromptForClassification(plm=copy.deepcopy(plm), template=template,\n",
    "                                       verbalizer=verbalizer)\n",
    "prompt_model = prompt_model.cuda()\n",
    "prompt_scores = [evaluate(prompt_model, val_dataloader)]\n",
    "prompt_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFOS10MLiVXJ",
    "outputId": "99855407-0f70-4ee6-b2d2-1d248f7f2d3f"
   },
   "outputs": [],
   "source": [
    "## Now generate a learning curve. loop over different values of k (total samples)\n",
    "## and calculate accuracy for each\n",
    "\n",
    "for k in sample_sizes:\n",
    "    # they are already shuffled, we can simply select the first k examples each time\n",
    "    train_sample = prompt_dataset['pos_train'][:k] + prompt_dataset['neg_train'][:k]\n",
    "    train_dataloader = PromptDataLoader(train_sample, template, tokenizer=tokenizer,\n",
    "                                    tokenizer_wrapper_class=WrapperClass, shuffle=True,\n",
    "                                    batch_size=4, seed=seed)\n",
    "\n",
    "    prompt_model = PromptForClassification(plm=copy.deepcopy(plm), template=template,\n",
    "                                         verbalizer=verbalizer, freeze_plm=False)\n",
    "    prompt_model = prompt_model.cuda()\n",
    "\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "      {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "      {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        tot_loss = 0\n",
    "        for step, inputs in enumerate(train_dataloader):\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "            logits = prompt_model(inputs)\n",
    "            labels = inputs['label']\n",
    "            loss = loss_func(logits, labels)\n",
    "            loss.backward()\n",
    "            tot_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    accuracy = evaluate(prompt_model, val_dataloader)\n",
    "    prompt_scores.append(accuracy)\n",
    "    print(prompt_scores)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nm3SSIriiVXJ"
   },
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4A0tlP3iVXJ"
   },
   "outputs": [],
   "source": [
    "## Scores for the plot in the paper\n",
    "\n",
    "# finetune_scores = [0.5091743119266054,\n",
    "#                    0.5068807339449541,\n",
    "#                    0.6548165137614679,\n",
    "#                    0.8486238532110092,\n",
    "#                    0.8623853211009175,\n",
    "#                    0.8738532110091743]\n",
    "\n",
    "# prompt_scores = [0.680045871559633,\n",
    "#                  0.6743119266055045,\n",
    "#                  0.786697247706422,\n",
    "#                  0.8474770642201835,\n",
    "#                  0.8520642201834863,\n",
    "#                  0.8658256880733946]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "31tU6QT0iVXJ",
    "outputId": "4e2ac156-0b96-4276-ae62-9c387a336f16"
   },
   "outputs": [],
   "source": [
    "# plot the prompt-based training and pre-train/finetuning learning curves\n",
    "# against each other\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax11 = fig1.add_subplot(111)\n",
    "\n",
    "x = [0] + sample_sizes\n",
    "ax11.plot(range(len(x)), finetune_scores, color='#cc0000', lw=2, ls='--', label='Head-based tuning')\n",
    "ax11.scatter(range(len(x)), finetune_scores, color='#cc0000')\n",
    "ax11.plot(range(len(x)), prompt_scores, color='#6d9eeb', lw=2, label='Prompt-based tuning')\n",
    "ax11.scatter(range(len(x)), prompt_scores, color='#6d9eeb')\n",
    "ax11.set_xticks(range(len(x)))\n",
    "ax11.set_xticklabels(x,fontsize=16)\n",
    "ax11.set_xlabel('# training examples (per class)',fontsize=20)\n",
    "\n",
    "ax11.set_yticks([0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "ax11.set_yticklabels(['0.5', '0.6', '0.7', '0.8', '0.9'],fontsize=16)\n",
    "ax11.set_ylabel('Test Set Accuracy',fontsize=20)\n",
    "\n",
    "ax11.xaxis.set_ticks_position('both')\n",
    "ax11.tick_params(axis='x', which='major', direction='in')\n",
    "ax11.tick_params(axis='x', which='minor', direction='in')\n",
    "ax11.yaxis.set_ticks_position('both')\n",
    "ax11.tick_params(axis='y', which='major', direction='in')\n",
    "ax11.tick_params(axis='y', which='minor', direction='in')\n",
    "\n",
    "plt.gca().yaxis.set_minor_locator(MultipleLocator(0.02))\n",
    "\n",
    "ax11.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CC43e6JLiVXK"
   },
   "source": [
    "## Named-entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FFCfAYMGlHg"
   },
   "source": [
    "### Head-based fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS0DTDXviVXK"
   },
   "source": [
    "#### Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQA2iXKA0x9z",
    "outputId": "42479984-cc4e-4832-d0b1-baf12556e7ce"
   },
   "outputs": [],
   "source": [
    "## Load CoNLL-2003 dataset from huggingface\n",
    "dataset = load_dataset('conll2003')\n",
    "\n",
    "## Create dictionary key for CoNLL-2003 NER-tags:\n",
    "id_to_label = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "label_to_id = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJ7pOexZ0zH6",
    "outputId": "c08eb168-bdc7-4845-e00c-e7109698e94e"
   },
   "outputs": [],
   "source": [
    "## Prepare the data using three steps.\n",
    "##   1) downsample train, test, val as desired.\n",
    "##   2) convert labels from dataset tokenization to BERT tokenization\n",
    "##   3) tokenize and pad the sentences.\n",
    "\n",
    "seed = 13\n",
    "\n",
    "TRN_SAMP = 1024\n",
    "VAL_SAMP = 500\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "SET_EXTRA_TOK_TO_MINUS_100 = False\n",
    "\n",
    "pad_length = 128\n",
    "\n",
    "#######\n",
    "\n",
    "## Tokenize sentences and return vectors necessary for the training loop\n",
    "def tokenize_function(tokens):\n",
    "    return tokenizer.encode_plus(tokens,\n",
    "                                 is_split_into_words = True,\n",
    "                                 pad_to_max_length = True,\n",
    "                                 max_length = pad_length,\n",
    "                                 return_attention_mask = True,\n",
    "                                 return_token_type_ids = True,\n",
    "                                 )\n",
    "\n",
    "def pad_label_example(tokenized_input, labels, label_all_tokens=True):\n",
    "    ## Look for tokens identified as \"None\" type -- set label to -100. Else,\n",
    "    ## use the label from the input label vector.\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "    label_ids = []\n",
    "    for i, word_idx in enumerate(word_ids):\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "        else:\n",
    "            label_ids.append(labels[i-1])\n",
    "    return label_ids\n",
    "\n",
    "## Determine for each word if BERT tokenization differs.\n",
    "def apply_bert_tok(og_tok_sent,og_lab):\n",
    "    newlab = []\n",
    "    ## Determine the tokenization for each word.\n",
    "    for i, t in enumerate(og_tok_sent):\n",
    "        ttok = tokenizer(' '+t+' ',add_special_tokens=False)['input_ids']\n",
    "        ## If the word splits to subwork tokens, extra spots in the labels.\n",
    "        for j in range(len(ttok)):\n",
    "            ## Can either set to -100 or set to same label as the original token.\n",
    "            if SET_EXTRA_TOK_TO_MINUS_100:\n",
    "                if j == 0: newlab.append(og_lab[i])\n",
    "                else: newlab.append(-100)\n",
    "            else:\n",
    "                newlab.append(og_lab[i])\n",
    "    return newlab\n",
    "\n",
    "## Convert labels to BERT tokenization.\n",
    "## Note the data comes pretokenized, but the split doesn't match BERT procedure.\n",
    "## So we tokenize every individual word to determine where word splitting occurs,\n",
    "## and create a new label vector to account for this.\n",
    "def bert_token_maker(dataset):\n",
    "    full_sents, tok_sents, pad_labs = [], [], []\n",
    "    input_ids, tkntype_ids, attn_masks = [], [], []\n",
    "    ## Update labels to reflect BERT tokenization\n",
    "    sents, labs = dataset['sentence'], dataset['labels']\n",
    "    new_labs = [apply_bert_tok(sents[i], labs[i]) for i in range(len(labs))]\n",
    "    ## Create encoded dictionaries for each sentence.\n",
    "    tok_dicts = [tokenize_function(s) for s in sents]\n",
    "\n",
    "    for td,l in zip(tok_dicts,new_labs):\n",
    "        ## Collect the original and tokenized sentence.\n",
    "        full_sents.append(tokenizer.decode(td['input_ids'],skip_special_tokens=True))\n",
    "        tok_sents.append([tokenizer.decode(td['input_ids'][i]) for i in range(len(td['input_ids']))])\n",
    "        ## Pad labels to align with tokenized sentences.\n",
    "        pad_labs.append(pad_label_example(td,l))\n",
    "        ## Collect other training requirements.\n",
    "        input_ids.append(td['input_ids'])\n",
    "        tkntype_ids.append(td['token_type_ids'])\n",
    "        attn_masks.append(td['attention_mask'])\n",
    "\n",
    "    dataset = Dataset.from_dict(\n",
    "            {'id': dataset['id'],\n",
    "             'sentence': full_sents,\n",
    "             'tokens': tok_sents,\n",
    "             'labels': pad_labs,\n",
    "             'input_ids': input_ids,\n",
    "             'token_type_ids': tkntype_ids,\n",
    "             'attention_mask': attn_masks\n",
    "             })\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def data_prep(dataset):\n",
    "\n",
    "    ## Remove unneeded columns\n",
    "    dataset = dataset.remove_columns([\"pos_tags\", \"chunk_tags\"])\n",
    "    dataset = dataset.rename_column(\"tokens\", \"sentence\")\n",
    "    dataset = dataset.rename_column(\"ner_tags\", \"labels\")\n",
    "\n",
    "    ## Downsample to a (pseudo)random subset.\n",
    "    dataset['train'] = dataset['train'].shuffle(seed=seed).select(range(TRN_SAMP))\n",
    "    dataset['validation'] = dataset['validation'].shuffle(seed=seed).select(range(VAL_SAMP))\n",
    "\n",
    "    ## Tokenize sentences and align labels.\n",
    "    dataset['train'] = bert_token_maker(dataset['train'])\n",
    "    dataset['validation'] = bert_token_maker(dataset['validation'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "tokenized_datasets = data_prep(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8pnkofx0VgZ",
    "outputId": "c45a6566-e167-411a-9998-a1e046aa9d17"
   },
   "outputs": [],
   "source": [
    "## We will try different numbers of samples for the learning curve\n",
    "shot_increments = 7\n",
    "sample_sizes = [0,] + [2**i for i in range(3, 4 + shot_increments)]\n",
    "sample_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd95w6OsNBsR"
   },
   "source": [
    "#### Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5GD5muUNBXs"
   },
   "outputs": [],
   "source": [
    "## Define F1-score metric\n",
    "\n",
    "def compute_ptft_f1(preds,labs):\n",
    "    preds_clean = preds.argmax(axis=2)[labs != -100]\n",
    "    labs_clean = labs[labs != -100]\n",
    "    # precision\n",
    "    pmask = np.isin(preds_clean, [1,3,5,7])\n",
    "    p = (preds_clean[pmask] == labs_clean[pmask])\n",
    "    p = p.astype(float).sum()/sum(pmask)\n",
    "    # recall\n",
    "    rmask = np.isin(labs_clean, [1,3,5,7])\n",
    "    r = (preds_clean[rmask] == labs_clean[rmask])\n",
    "    r = r.astype(float).sum()/sum(rmask)\n",
    "    # f1\n",
    "    return 2.*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-Pij4BAr_O-Q",
    "outputId": "7aa37a33-48bf-439b-ccff-2c8a63ff5f6b"
   },
   "outputs": [],
   "source": [
    "## Set parameters for training loop, and load BERT model\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "training_args = TrainingArguments(\"trainer\")\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-cased',\n",
    "                                                    num_labels=len(label_to_id))\n",
    "\n",
    "## Loop over different samples of k\n",
    "finetune_scores = []\n",
    "for i, k in enumerate(sample_sizes):\n",
    "    if k == 0: samps = range(0) ## zero-shot\n",
    "    else: samps = range(sample_sizes[i-1],k) ## iterative training\n",
    "    train_sample = tokenized_datasets['train'].select(samps)\n",
    "    training_args = TrainingArguments(\"trainer\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        train_dataset=train_sample,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    ## If k==0, do zero-shot testing. Otherwise, activate training.\n",
    "    if k > 0:\n",
    "        trainer.train()\n",
    "    preds = trainer.predict(tokenized_datasets['validation'])\n",
    "    f1 = compute_ptft_f1(preds.predictions, preds.label_ids)\n",
    "    finetune_scores.append(f1)\n",
    "    print(finetune_scores)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCfwo7SINIcj"
   },
   "source": [
    "### Prompt-based fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuKksfuLiVXL"
   },
   "source": [
    "#### Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFKjNUDyGnTm"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('conll2003')\n",
    "\n",
    "id_to_label = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "label_to_id = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1lIqaBt7x8Y"
   },
   "outputs": [],
   "source": [
    "## Create mapping for entity ids to indexes 0-4.\n",
    "label_to_label = {0: 0, ## non-entity\n",
    "                  1: 1, ## person\n",
    "                  3: 2, ## organization\n",
    "                  5: 3, ## location\n",
    "                  7: 4} ## misc\n",
    "TRN_SAMP = 1024\n",
    "VAL_SAMP = 500\n",
    "seed = 13\n",
    "\n",
    "## Identify each entity in each sample, and determine if it is one or multiple\n",
    "## tokens long. this allows us to generate individual prompts for each entity.\n",
    "## Save each entity along with its NER tag.\n",
    "def gen_entity_tags(sample):\n",
    "    tokens, labels = sample['tokens'], sample['ner_tags']\n",
    "    total = len(tokens)\n",
    "    entities, tags = [], []\n",
    "    for idx, (t, l) in enumerate(zip(tokens, labels)):\n",
    "        ## Collect non-entities\n",
    "        if l == 0:\n",
    "            entities.append(t)\n",
    "            tags.append(label_to_label[l])\n",
    "            continue\n",
    "\n",
    "        ## Collect entites\n",
    "        if l in (1,3,5,7):\n",
    "            ## If entity is final token, save\n",
    "            if idx == total-1:\n",
    "                entities.append(t)\n",
    "                tags.append(label_to_label[l])\n",
    "                continue\n",
    "\n",
    "            ## If entity is one token, save.\n",
    "            if labels[idx+1] != l+1:\n",
    "                entities.append(t)\n",
    "                tags.append(label_to_label[l])\n",
    "                continue\n",
    "\n",
    "            ## If entity continues to the next token, find how long it goes.\n",
    "            cont = True\n",
    "            extra = 1\n",
    "            while(cont):\n",
    "                ## Check if we've reached the end\n",
    "                if idx+extra == total-1:\n",
    "                    cont = False\n",
    "                elif labels[idx+extra+1] == l+1:\n",
    "                    extra += 1\n",
    "                else:\n",
    "                    cont = False\n",
    "            whole_ent = ' '.join(tokens[idx:idx+extra+1])\n",
    "            entities.append(whole_ent)\n",
    "            tags.append(label_to_label[l])\n",
    "\n",
    "    return entities, tags\n",
    "\n",
    "\n",
    "## Create a dictionary-based dataset to save each entity, its tag, and its\n",
    "## source sentence.\n",
    "def prompt_data_prep(dataset):\n",
    "    ## Downsample\n",
    "    dataset['train'] = dataset['train'].shuffle(seed=seed).select(range(TRN_SAMP))\n",
    "    dataset['validation'] = dataset['validation'].shuffle(seed=seed).select(range(VAL_SAMP))\n",
    "\n",
    "    ## Loop through data to locate entities and save tags\n",
    "    pr_data = {}\n",
    "    for split in ['train', 'validation']:\n",
    "        pr_data[split] = []\n",
    "        for i, samp in enumerate(dataset[split]):\n",
    "            entities, tags = gen_entity_tags(samp)\n",
    "            sentence = ' '.join(entities)\n",
    "\n",
    "            ## Save entities and tags into openprompt InputExamples\n",
    "            for entity, tag in zip(entities,tags):\n",
    "                input_example = InputExample(text_a = sentence,\n",
    "                                             text_b = entity,\n",
    "                                             label = tag,\n",
    "                                             guid=i,\n",
    "                                             )\n",
    "                pr_data[split].append(input_example)\n",
    "\n",
    "    return pr_data\n",
    "\n",
    "prompt_dataset = prompt_data_prep(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CIQDQqQiVXM"
   },
   "source": [
    "#### Prompt-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAiFkS1q4VAw",
    "outputId": "c506890d-647f-4d97-8767-f6d50f057fec"
   },
   "outputs": [],
   "source": [
    "# load the BERT prompt model\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-cased\")\n",
    "wrapped_tokenizer = WrapperClass(max_seq_length=128,\n",
    "                                 decoder_max_length=3,\n",
    "                                 tokenizer=tokenizer,\n",
    "                                 truncate_method=\"head\")\n",
    "\n",
    "# create a cloze template for training and testing\n",
    "template_text = '{\"placeholder\": \"text_a\"}. {\"placeholder\": \"text_b\"} is a {\"mask\"} entity.'\n",
    "template = ManualTemplate(tokenizer=tokenizer, text=template_text)\n",
    "\n",
    "# define verbalizer corresponding to different named entity classes\n",
    "verbalizer = ManualVerbalizer(tokenizer, num_classes=5,\n",
    "                                label_words=[\n",
    "                                    ['non-'],\n",
    "                                    ['person'],\n",
    "                                    ['organization'],\n",
    "                                    ['location'],\n",
    "                                    ['other'],\n",
    "                                ])\n",
    "\n",
    "# create a validation dataloader\n",
    "val_dataloader = PromptDataLoader(prompt_dataset['validation'], template, tokenizer=tokenizer,\n",
    "                                  tokenizer_wrapper_class=WrapperClass, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zUrV00f7eZ0"
   },
   "outputs": [],
   "source": [
    "# define F1-score metric\n",
    "def compute_prompt_f1(model, val_dataloader):\n",
    "    model.eval()\n",
    "    allpreds, alllabels = [], []\n",
    "    with torch.no_grad():\n",
    "        for step, inputs in enumerate(val_dataloader):\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "            logits = model(inputs)\n",
    "            labels = inputs['label']\n",
    "            alllabels.extend(labels.cpu().tolist())\n",
    "            allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "            if step%10 ==0: print(step, 'of', len(val_dataloader), 'done')\n",
    "    labs_clean, preds_clean = np.array(alllabels), np.array(allpreds)\n",
    "    # precision\n",
    "    pmask = (preds_clean != 0)\n",
    "    p = (preds_clean[pmask] == labs_clean[pmask])\n",
    "    p = p.astype(float).sum()/sum(pmask)\n",
    "    # recall\n",
    "    rmask = (labs_clean != 0)\n",
    "    r = (preds_clean[rmask] == labs_clean[rmask])\n",
    "    r = r.astype(float).sum()/sum(rmask)\n",
    "    # f1\n",
    "    return 2.*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RI5LWM775Pq-",
    "outputId": "559a7a8b-e81c-4e23-ee92-842ddfbed03a"
   },
   "outputs": [],
   "source": [
    "# loop over different values of k and save accuracy for each\n",
    "\n",
    "prompt_model = PromptForClassification(plm=copy.deepcopy(plm), template=template,\n",
    "                                        verbalizer=verbalizer, freeze_plm=False)\n",
    "prompt_model = prompt_model.cuda()\n",
    "\n",
    "prompt_scores = []\n",
    "sample_sizes = [0, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "for ind, k in enumerate(sample_sizes):\n",
    "    ## If zero-shot, proceed to predictions. else, go through training loop\n",
    "    if k != 0:\n",
    "        ## define dataset and build dataloader\n",
    "        if ind == 0: k0 = 0\n",
    "        else: k0 = sample_sizes[ind-1]\n",
    "        train_sample = [samp for samp in prompt_dataset['train'] if k0 <= samp.guid < k]\n",
    "        train_dataloader = PromptDataLoader(train_sample, template, tokenizer=tokenizer,\n",
    "                                                                    tokenizer_wrapper_class=WrapperClass, shuffle=True,\n",
    "                                                                    batch_size=4, seed=seed)\n",
    "\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
    "\n",
    "        for epoch in range(5):\n",
    "            tot_loss = 0\n",
    "            for step, inputs in enumerate(train_dataloader):\n",
    "                    if use_cuda:\n",
    "                            inputs = inputs.cuda()\n",
    "                    logits = prompt_model(inputs)\n",
    "                    labels = inputs['label']\n",
    "                    loss = loss_func(logits, labels)\n",
    "                    loss.backward()\n",
    "                    tot_loss += loss.item()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "    prompt_scores.append(compute_prompt_f1(prompt_model, val_dataloader))\n",
    "    print(prompt_scores)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pErMqdKEiVXR"
   },
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIYK2hItiVXR"
   },
   "outputs": [],
   "source": [
    "# Scores for the plot in the paper\n",
    "\n",
    "finetune_scores = [0.06870229007633588,\n",
    "                   0.049224544841537425,\n",
    "                   0.0022522522522522522,\n",
    "                   0.003370786516853933,\n",
    "                   0.3323353293413174,\n",
    "                   0.5577981651376147,\n",
    "                   0.7157034442498541,\n",
    "                   0.7894438138479001,\n",
    "                   0.8526011560693642]\n",
    "\n",
    "prompt_scores = [0.07118375955707884,\n",
    "                 0.5788359788359789,\n",
    "                 0.6481854838709677,\n",
    "                 0.727367870225013,\n",
    "                 0.7866666666666666,\n",
    "                 0.8365437534397359,\n",
    "                 0.8671706263498921,\n",
    "                 0.8303769401330378,\n",
    "                 0.855135135135135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "VvaMyJUnwjx4",
    "outputId": "b9a023c3-781b-496f-ff4a-ef34271c4e3b"
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax11 = fig1.add_subplot(111)\n",
    "\n",
    "x = sample_sizes\n",
    "ax11.plot(range(len(x)), finetune_scores, color='#cc0000', lw=2, ls='--', label='Head-based tuning')\n",
    "ax11.scatter(range(len(x)), finetune_scores, color='#cc0000')\n",
    "ax11.plot(range(len(x)), prompt_scores, color='#6d9eeb', lw=2, label='Prompt-based tuning')\n",
    "ax11.scatter(range(len(x)), prompt_scores, color='#6d9eeb')\n",
    "\n",
    "ax11.set_xticks(range(len(x)))\n",
    "ax11.set_xticklabels(x,fontsize=16)\n",
    "ax11.set_xlabel('# training examples (per class)',fontsize=20)\n",
    "\n",
    "ax11.set_ylim(-0.04,1.08)\n",
    "ax11.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax11.set_yticklabels(['0.0', '0.2', '0.4', '0.6', '0.8', '1.0'],fontsize=16)\n",
    "ax11.set_ylabel('Test Set F1-score',fontsize=20)\n",
    "\n",
    "ax11.xaxis.set_ticks_position('both')\n",
    "ax11.tick_params(axis='x', which='major', direction='in')\n",
    "ax11.tick_params(axis='x', which='minor', direction='in')\n",
    "ax11.yaxis.set_ticks_position('both')\n",
    "ax11.tick_params(axis='y', which='major', direction='in')\n",
    "ax11.tick_params(axis='y', which='minor', direction='in')\n",
    "\n",
    "plt.gca().yaxis.set_minor_locator(MultipleLocator(0.04))\n",
    "\n",
    "ax11.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TY7PlWl5-LKF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03a30e0f3629404fad68bca87cd7df83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd09844151a54644b8a5c6cb7fc5ed29",
      "placeholder": "​",
      "style": "IPY_MODEL_901f44c6889744859993aaeb6100056f",
      "value": "Downloading: 100%"
     }
    },
    "0958a86012ae4b8eb2bccc8773959acd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b84311849f84b2f8ead61bee9fe76ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "154f86fa79a24a878eab56c61be42a14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43eddbbd7b994bf280259963d8b90a0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_471803e92edf48248a90d934549b2a89",
      "placeholder": "​",
      "style": "IPY_MODEL_7e710035aecf4dcdb9a89f2a94706f45",
      "value": "Map: 100%"
     }
    },
    "471803e92edf48248a90d934549b2a89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e710035aecf4dcdb9a89f2a94706f45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ab2c16098b0433a8ee2bffc4533183a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91d59fe84a634ec293216cfaee9c333a",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e6781e07a6314e51b3fd91e3f6ed4ae8",
      "value": 435779157
     }
    },
    "901f44c6889744859993aaeb6100056f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91d59fe84a634ec293216cfaee9c333a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f4371ee9536450e96dc2d404221e62f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad433567c0dc4b16a4c7a78fe9d1d2d7",
      "placeholder": "​",
      "style": "IPY_MODEL_b9bc96d64de94241a3727252642bf3ec",
      "value": " 872/872 [00:00&lt;00:00, 8097.81 examples/s]"
     }
    },
    "a2e31e39f305471f9ca3d12b7a5ca1bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae4146821f994598ab561b975ad2f9f2",
      "placeholder": "​",
      "style": "IPY_MODEL_f31f50d874a046b294537c1fe6950fb7",
      "value": " 416M/416M [00:08&lt;00:00, 49.1MB/s]"
     }
    },
    "ad433567c0dc4b16a4c7a78fe9d1d2d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae4146821f994598ab561b975ad2f9f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9bc96d64de94241a3727252642bf3ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd09844151a54644b8a5c6cb7fc5ed29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3942f7ec3f44fb7b1cc36959b825420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b84311849f84b2f8ead61bee9fe76ae",
      "max": 872,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0958a86012ae4b8eb2bccc8773959acd",
      "value": 872
     }
    },
    "d84a270ea3ea4156acc42a1fb79a233d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd9e2008ea70466d8f763e59a6e71e81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_03a30e0f3629404fad68bca87cd7df83",
       "IPY_MODEL_8ab2c16098b0433a8ee2bffc4533183a",
       "IPY_MODEL_a2e31e39f305471f9ca3d12b7a5ca1bc"
      ],
      "layout": "IPY_MODEL_d84a270ea3ea4156acc42a1fb79a233d"
     }
    },
    "e6781e07a6314e51b3fd91e3f6ed4ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f31f50d874a046b294537c1fe6950fb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc3675c8cdd34ea38ac3f9c07fd0f8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43eddbbd7b994bf280259963d8b90a0e",
       "IPY_MODEL_d3942f7ec3f44fb7b1cc36959b825420",
       "IPY_MODEL_9f4371ee9536450e96dc2d404221e62f"
      ],
      "layout": "IPY_MODEL_154f86fa79a24a878eab56c61be42a14"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
